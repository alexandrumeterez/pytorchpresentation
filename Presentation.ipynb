{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transfer Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have seen that nowadays, we can throw neural networks at pretty much every problem we face. Classification, detection, regression, generation and many others, they have shown massive improvement by using deep learning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What about the domains where we can use this? Surely there must be more than computer science. Indeed there are:\n",
    "1. Medicine - tumor detection: https://arxiv.org/abs/1801.03230\n",
    "2. Art - generate pictures: https://arxiv.org/abs/1406.2661\n",
    "3. Finance - fraud detection: https://arxiv.org/abs/1804.07481\n",
    "4. UI/UX improvements - GUI prototyping: https://arxiv.org/pdf/1802.02312\n",
    "and many others."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, a world where we could just throw such a marvelous algorithm at any problem and obtain great results without any prerequisite seems utopian. And indeed it is."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 2 severe drawbacks of deep neural nets:\n",
    "1. they require __massive ammounts of data__\n",
    "2. they take __an unrealistically long time to train on consumer PCs__\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's where __transfer learning__ comes into play."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What it is"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transfer learning is a way to extract the abstract knowledge from one learning domain or task and reuse of that knowledge in a related domain or taks. This is similar to how humans learn from a very early age."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In __children__, we see this behaviour when they learn to play an instrument. In [this study](http://www.pnas.org/content/113/19/5212), we can see that children who learn how to play music when they are little posses a significant advantage in verbal and lingual learning skills over the ones that don't.\n",
    "In __adults__, the same behaviour is spotted when we learn languages. The more languages you add to your vocabulary, the easier the next ones are to learn."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is commonly known as __learning to learn__."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Differences between the traditional setup and the transfer learning setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the __traditional setup__, you get your training data and you build a neural network initialized randomly then perform a number of epochs of forward/backward propagation in which you modify the weights of each neuron in order to minimize the loss function of your choice.\n",
    "![Traditional setup](images/traditional_ml_setup.png \"Traditional setup\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In a __transfer learning__ setup, you get a __trained__ neural network and through some process, you reuse those weights for your new task.\n",
    "![Transfer learning setup](images/transfer_learning_setup.png \"Transfer learning setup\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How it works"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 3 major transfer learning scenarios used in practice(sorted by the ammount of data and time needed to train):\n",
    "1. __Pretrained models__: Require no new data or time to train. Just take a pretrained network(VGG16, Inception, ResNet etc.) and throw an input image at it and read the output distribution.\n",
    "2. __ConvNet as fixed feature extractor__: Require a moderate amount of data and time. Suppose you take a ConvNet pretrained on ImageNet(a large image dataset containing 1000 classes). You want to specialize this network on 3 new classes of your own desire. What you do is you take out the last fully connected layer(the one that gives the distribution over the 1000 classes) and instead add a new fully connected layer of with the size equal to the new number of classes and randomly initialize it. Afterwards, you freeze the rest of the network and simply do backprop on the new layer.\n",
    "3. __Fine-tuning the ConvNet__: Most intensive computationally and data hungry. Same action as the above regarding the last layer, but now you do backprop throughout the whole network(or a larger part of the network instead of only the last layer)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The biggest benefit of using any of the above methods is that we drastically __improve training time__ and __reduce the massive of amount of data__ needed to train a neural network(__>1.000.000 examples__) to the order of thousands-tens of __thousands__ needed to specialize."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Why it works"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_This is most easily explained visually, using ConvNets, but this concept applies to other types of layers as well._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start with some basic anatomy of the visual cortex. Citing this article from Wikipedia, _\"The visual cortex of the brain is a part of the cerebral cortex that processes visual information. It is located in the occipital lobe. Visual nerves run straight from the eye to the primary visual cortex to the Visual Association cortex\"_."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![visualcortex.png](images/visualcortex.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Furthermore, the visual cortex is part of the __visual system__. _\"The visual system is the part of the central nervous system which gives organisms the ability to process visual detail, as well as enabling the formation of several non-image photo response functions. It detects and interprets information from visible light to build a representation of the surrounding environment.\"_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### What does this have to do with neural nets?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ConvNets came to exist because of the need to process bigger images. You can't unroll a 512x512 image and put it through a full-connected layer. It would require 512x512x(fully-connected size) to update. And this is only one layer. It's obvious that it doesn't scale well. By applying strided kernels, we can capture local parts of the image and retain enough information to obtain a good(if not better) inference accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "They aren't inspired from the visual system of the human in any aspect. Yet they share similar results. How? _\"Some authors claim that simple cells in the visual cortex of mammalian brains can be modeled by Gabor functions. Thus, image analysis with Gabor filters is thought by some to be similar to perception in the human visual system.\"_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is a Gabor filter? _\"A linear filter used for texture analysis, which means that it basically analyzes whether there are any specific frequency content in the image in specific directions in a __localized region around the point or region of analysis.__\"_"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![gabor_filter.png](images/gabor_filter.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's take a look inside the weights of the first few layers of the AlexNet network(trained on the ImageNet dataset). What you will notice are similarities in the weights to Gabor filters. Why? __Because a ConvNet builds the inference hierarchically, from base features to more complex ones and every image shares the same basic features__. What this means is that we can share the weights(as in sharing the knowledge) between two neural networks and then specialize for our classes and have it be advantageous."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![weights.jpeg](images/weights.jpeg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## That's how transfer learning works. Time to practice."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For today, I have prepared a small and fun practical exercise that we can all do on our personal laptops.\n",
    "1. First we will collect some data. The data we will get consists of images of our 3 positions of each one's thumb: __pointing up, horizontal and pointing down__, about 2000 pics of each.\n",
    "2. We will train a neural network(or at least attempt) with just these pictures - and fail terribly\n",
    "3. We will apply the last 2 methods of transfer learning and compare the results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# References"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. http://cs231n.github.io/understanding-cnn/\n",
    "2. http://cs231n.stanford.edu/slides/2017/cs231n_2017_lecture12.pdf\n",
    "3. http://cs231n.github.io/convolutional-networks/\n",
    "4. https://en.wikipedia.org/wiki/Visual_cortex\n",
    "5. https://pytorch.org/tutorials/beginner/transfer_learning_tutorial.html\n",
    "6. https://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks.pdf\n",
    "7. https://opencv.org/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
